{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/python2/lib/python2.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import load_boston\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "boston = load_boston()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dataset = pd.DataFrame(boston.data,columns=boston.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset['target'] = boston.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CRIM</th>\n",
       "      <th>ZN</th>\n",
       "      <th>INDUS</th>\n",
       "      <th>CHAS</th>\n",
       "      <th>NOX</th>\n",
       "      <th>RM</th>\n",
       "      <th>AGE</th>\n",
       "      <th>DIS</th>\n",
       "      <th>RAD</th>\n",
       "      <th>TAX</th>\n",
       "      <th>PTRATIO</th>\n",
       "      <th>B</th>\n",
       "      <th>LSTAT</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>296.0</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>17.8</td>\n",
       "      <td>392.83</td>\n",
       "      <td>4.03</td>\n",
       "      <td>34.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CRIM    ZN  INDUS  CHAS    NOX     RM   AGE     DIS  RAD    TAX  \\\n",
       "0  0.00632  18.0   2.31   0.0  0.538  6.575  65.2  4.0900  1.0  296.0   \n",
       "1  0.02731   0.0   7.07   0.0  0.469  6.421  78.9  4.9671  2.0  242.0   \n",
       "2  0.02729   0.0   7.07   0.0  0.469  7.185  61.1  4.9671  2.0  242.0   \n",
       "3  0.03237   0.0   2.18   0.0  0.458  6.998  45.8  6.0622  3.0  222.0   \n",
       "4  0.06905   0.0   2.18   0.0  0.458  7.147  54.2  6.0622  3.0  222.0   \n",
       "\n",
       "   PTRATIO       B  LSTAT  target  \n",
       "0     15.3  396.90   4.98    24.0  \n",
       "1     17.8  396.90   9.14    21.6  \n",
       "2     17.8  392.83   4.03    34.7  \n",
       "3     18.7  394.63   2.94    33.4  \n",
       "4     18.7  396.90   5.33    36.2  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "observations = len(dataset)\n",
    "variables = dataset.columns[:-1]\n",
    "X = dataset.ix[:,:-1]\n",
    "y = dataset['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно делать модель просто передавая матрицы, но тогда нужно добавлять константу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xc = sm.add_constant(X)\n",
    "linear_regression = sm.OLS(y,Xc)\n",
    "fitted_model = linear_regression.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>target</td>      <th>  R-squared:         </th> <td>   0.741</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.734</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   108.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 13 May 2016</td> <th>  Prob (F-statistic):</th> <td>6.95e-135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:36:57</td>     <th>  Log-Likelihood:    </th> <td> -1498.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   506</td>      <th>  AIC:               </th> <td>   3026.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   492</td>      <th>  BIC:               </th> <td>   3085.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   36.4911</td> <td>    5.104</td> <td>    7.149</td> <td> 0.000</td> <td>   26.462    46.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CRIM</th>      <td>   -0.1072</td> <td>    0.033</td> <td>   -3.276</td> <td> 0.001</td> <td>   -0.171    -0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ZN</th>        <td>    0.0464</td> <td>    0.014</td> <td>    3.380</td> <td> 0.001</td> <td>    0.019     0.073</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>INDUS</th>     <td>    0.0209</td> <td>    0.061</td> <td>    0.339</td> <td> 0.735</td> <td>   -0.100     0.142</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>CHAS</th>      <td>    2.6886</td> <td>    0.862</td> <td>    3.120</td> <td> 0.002</td> <td>    0.996     4.381</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>NOX</th>       <td>  -17.7958</td> <td>    3.821</td> <td>   -4.658</td> <td> 0.000</td> <td>  -25.302   -10.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RM</th>        <td>    3.8048</td> <td>    0.418</td> <td>    9.102</td> <td> 0.000</td> <td>    2.983     4.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>AGE</th>       <td>    0.0008</td> <td>    0.013</td> <td>    0.057</td> <td> 0.955</td> <td>   -0.025     0.027</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>DIS</th>       <td>   -1.4758</td> <td>    0.199</td> <td>   -7.398</td> <td> 0.000</td> <td>   -1.868    -1.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RAD</th>       <td>    0.3057</td> <td>    0.066</td> <td>    4.608</td> <td> 0.000</td> <td>    0.175     0.436</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>TAX</th>       <td>   -0.0123</td> <td>    0.004</td> <td>   -3.278</td> <td> 0.001</td> <td>   -0.020    -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>PTRATIO</th>   <td>   -0.9535</td> <td>    0.131</td> <td>   -7.287</td> <td> 0.000</td> <td>   -1.211    -0.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>B</th>         <td>    0.0094</td> <td>    0.003</td> <td>    3.500</td> <td> 0.001</td> <td>    0.004     0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LSTAT</th>     <td>   -0.5255</td> <td>    0.051</td> <td>  -10.366</td> <td> 0.000</td> <td>   -0.625    -0.426</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>178.029</td> <th>  Durbin-Watson:     </th> <td>   1.078</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 782.015</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.521</td>  <th>  Prob(JB):          </th> <td>1.54e-170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.276</td>  <th>  Cond. No.          </th> <td>1.51e+04</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 target   R-squared:                       0.741\n",
       "Model:                            OLS   Adj. R-squared:                  0.734\n",
       "Method:                 Least Squares   F-statistic:                     108.1\n",
       "Date:                Fri, 13 May 2016   Prob (F-statistic):          6.95e-135\n",
       "Time:                        10:36:57   Log-Likelihood:                -1498.8\n",
       "No. Observations:                 506   AIC:                             3026.\n",
       "Df Residuals:                     492   BIC:                             3085.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     36.4911      5.104      7.149      0.000        26.462    46.520\n",
       "CRIM          -0.1072      0.033     -3.276      0.001        -0.171    -0.043\n",
       "ZN             0.0464      0.014      3.380      0.001         0.019     0.073\n",
       "INDUS          0.0209      0.061      0.339      0.735        -0.100     0.142\n",
       "CHAS           2.6886      0.862      3.120      0.002         0.996     4.381\n",
       "NOX          -17.7958      3.821     -4.658      0.000       -25.302   -10.289\n",
       "RM             3.8048      0.418      9.102      0.000         2.983     4.626\n",
       "AGE            0.0008      0.013      0.057      0.955        -0.025     0.027\n",
       "DIS           -1.4758      0.199     -7.398      0.000        -1.868    -1.084\n",
       "RAD            0.3057      0.066      4.608      0.000         0.175     0.436\n",
       "TAX           -0.0123      0.004     -3.278      0.001        -0.020    -0.005\n",
       "PTRATIO       -0.9535      0.131     -7.287      0.000        -1.211    -0.696\n",
       "B              0.0094      0.003      3.500      0.001         0.004     0.015\n",
       "LSTAT         -0.5255      0.051    -10.366      0.000        -0.625    -0.426\n",
       "==============================================================================\n",
       "Omnibus:                      178.029   Durbin-Watson:                   1.078\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              782.015\n",
       "Skew:                           1.521   Prob(JB):                    1.54e-170\n",
       "Kurtosis:                       8.276   Cond. No.                     1.51e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.51e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Name|Description|\n",
    "|--|-------------------------------|\n",
    "|Df Residuals |Степени свободы residuals (остатки, невязки, ошибки, (y-y_pred)).Рассчитываются, как n строк - n переменных|\n",
    "|Df model |Степени свободы модели, рассчитывается как n переменных -1 (исключаем константу)|\n",
    "|R-squared |Коэффициент детерминации. Показывает насколько модель лучше по сравнению с просто средним значением по всем ответам|\n",
    "|Adj. R-squared: |Коэффициент детерминации c поправками. Дело в том, что чем больше в моделе переменных - тем больше будет становиться R-squared. Adj. R-squared рассчитывается с поправкой на кол-во переменных и показывает более реальное значение. Он всегда ниже обычного и когда мы работаем с множественной регрессией, то смотреть нужно именно на него. Так же есть правило, что если разница между двумя коэффициентами детерминации больше 20%, то в моделе присутствуют redundunt переменные, т.е. переменные, которые не окзазывают никакого влияния на целевую переменную|\n",
    "|F-statistic: |F статистика для нулевой гипотезы, что все коэффициенты (кроме константы) равны нулю. Т.е. гипотеза о том, что модель не отличается от простого среднего.|\n",
    "|Prob (F-statistic):|Вероятность получить F статиску из предыдущего пункта просто случайно. Если эта величина мала, то есть основания считать, что модель лучше чем среднее. Порог 0.05 применим так же как и во всех случаях с гипотезами и p-value|\n",
    "|Log-Likelihood:|Функция логистических потерь. (надо проверить)|\n",
    "|AIC:|[Akaike Information Criterion](https://ru.wikipedia.org/wiki/Информационный_критерий_Акаике). Чем меньше - тем лучше. Полезен для сравнения моделей и статистического отбора переменных.|\n",
    "|BIC:|[Bayesian Information Criterion](https://ru.wikipedia.org/wiki/Информационный_критерий). Смысл такой же, как и предыщего критерия. Больше штрафует модели с большим кол-во переменных|\n",
    "|coef: |The estimated coefficient|\n",
    "|std err: |The standard error of the estimate of the coefficient; the larger it is, the more uncertain the estimation of the coefficient|\n",
    "|t: |The t-statistic value, a measure indicating whether the coefficient true value is different from zero|\n",
    "|P > t: |The p-value indicating the probability that the coefficient is different from zero just by chance|\n",
    "|[95.0% Conf. Interval]: |The lower and upper values of the coefficient, considering 95% of all the chances of having different observations and so different estimated coefficients|\n",
    "|Omnibus: |Это совмещенный тест для kurtosis и skew. [Omnibus](https://en.wikipedia.org/wiki/D%27Agostino%27s_K-squared_test) По сути это тес на нормальность.|\n",
    "|Prob(Omnibus):|Вероятность получить такую статистику из нормального распределения. Кстати, нужно понимать, что все тесты из последней таблице выполнены для residuals!!!|\n",
    "|Skew:|Мера симметрии остатков относительно стреднего. Для симметричных распределения должно быть около 0. Положительно значение говорить о длинном правом хвосте, отрицательно - о левом|\n",
    "|Kurtosis:|Мера формы распределения residuals. Колоколобразная форма имеет 0 kurtosis, Отрицательное значение говорит о плоской форме. Положительное - о большом количестве пиков.|\n",
    "|[Durbin-Watson](https://ru.wikipedia.org/wiki/Критерий_Дарбина_—_Уотсона)|Тест на автокорреляцию среди resuduals. Используется при анализе временных рядов.|\n",
    "| Jarque-Bera (JB):|[Jarque-Bera](https://ru.wikipedia.org/wiki/Тест_Харке_—_Бера). Тест на нормальность resuduals, так же совмещающий skew и kurtosis. |\n",
    "|Prob(JB):|Веороятноть получить такую статистику из норм распр.|\n",
    "|Cond. No.|Тест на мультиколлениарность. Если больше 30, то ясный сигнал о том, что есть мульти коллениарность.|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "А можно использовать другой интерфейс и передавать формулу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO + B + LSTAT'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' + '.join(dataset.columns[:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formula = 'target ~ CRIM + ZN + INDUS + CHAS + NOX + RM + AGE + DIS + RAD + TAX + PTRATIO + B + LSTAT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "linear_regression = smf.ols(formula,dataset)\n",
    "fitted_model = linear_regression.fit()\n",
    "correlation_matrix = X.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             CRIM        ZN     INDUS      CHAS       NOX        RM       AGE  \\\n",
      "CRIM     1.000000 -0.199458  0.404471 -0.055295  0.417521 -0.219940  0.350784   \n",
      "ZN      -0.199458  1.000000 -0.533828 -0.042697 -0.516604  0.311991 -0.569537   \n",
      "INDUS    0.404471 -0.533828  1.000000  0.062938  0.763651 -0.391676  0.644779   \n",
      "CHAS    -0.055295 -0.042697  0.062938  1.000000  0.091203  0.091251  0.086518   \n",
      "NOX      0.417521 -0.516604  0.763651  0.091203  1.000000 -0.302188  0.731470   \n",
      "RM      -0.219940  0.311991 -0.391676  0.091251 -0.302188  1.000000 -0.240265   \n",
      "AGE      0.350784 -0.569537  0.644779  0.086518  0.731470 -0.240265  1.000000   \n",
      "DIS     -0.377904  0.664408 -0.708027 -0.099176 -0.769230  0.205246 -0.747881   \n",
      "RAD      0.622029 -0.311948  0.595129 -0.007368  0.611441 -0.209847  0.456022   \n",
      "TAX      0.579564 -0.314563  0.720760 -0.035587  0.668023 -0.292048  0.506456   \n",
      "PTRATIO  0.288250 -0.391679  0.383248 -0.121515  0.188933 -0.355501  0.261515   \n",
      "B       -0.377365  0.175520 -0.356977  0.048788 -0.380051  0.128069 -0.273534   \n",
      "LSTAT    0.452220 -0.412995  0.603800 -0.053929  0.590879 -0.613808  0.602339   \n",
      "\n",
      "              DIS       RAD       TAX   PTRATIO         B     LSTAT  \n",
      "CRIM    -0.377904  0.622029  0.579564  0.288250 -0.377365  0.452220  \n",
      "ZN       0.664408 -0.311948 -0.314563 -0.391679  0.175520 -0.412995  \n",
      "INDUS   -0.708027  0.595129  0.720760  0.383248 -0.356977  0.603800  \n",
      "CHAS    -0.099176 -0.007368 -0.035587 -0.121515  0.048788 -0.053929  \n",
      "NOX     -0.769230  0.611441  0.668023  0.188933 -0.380051  0.590879  \n",
      "RM       0.205246 -0.209847 -0.292048 -0.355501  0.128069 -0.613808  \n",
      "AGE     -0.747881  0.456022  0.506456  0.261515 -0.273534  0.602339  \n",
      "DIS      1.000000 -0.494588 -0.534432 -0.232471  0.291512 -0.496996  \n",
      "RAD     -0.494588  1.000000  0.910228  0.464741 -0.444413  0.488676  \n",
      "TAX     -0.534432  0.910228  1.000000  0.460853 -0.441808  0.543993  \n",
      "PTRATIO -0.232471  0.464741  0.460853  1.000000 -0.177383  0.374044  \n",
      "B        0.291512 -0.444413 -0.441808 -0.177383  1.000000 -0.366087  \n",
      "LSTAT   -0.496996  0.488676  0.543993  0.374044 -0.366087  1.000000  \n"
     ]
    }
   ],
   "source": [
    "print correlation_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Чтобы детектить зависимоть среди переменных строят хит-мэп из матрицы корреляций с порогом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def visualize_correlation_matrix(data, hurdle = 0.0):\n",
    "    R = np.corrcoef(data, rowvar=0)\n",
    "    R[np.where(np.abs(R)<hurdle)] = 0.0\n",
    "    heatmap = plt.pcolor(R, cmap=mpl.cm.coolwarm, alpha=0.8)\n",
    "    heatmap.axes.set_frame_on(False)\n",
    "    heatmap.axes.set_yticks(np.arange(R.shape[0]) + 0.5, minor=False)\n",
    "    heatmap.axes.set_xticks(np.arange(R.shape[1]) + 0.5, minor=False)\n",
    "    heatmap.axes.set_xticklabels(variables, minor=False)\n",
    "    plt.xticks(rotation=90)\n",
    "    heatmap.axes.set_yticklabels(variables, minor=False)\n",
    "    plt.tick_params(axis='both', which='both', bottom='off', \\\n",
    "                    top='off', left = 'off', right = 'off')\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAEjCAYAAAA2Uaa4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuT48MTjnnOvDE4Nzzrk+/n+jABLAihMP9QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11b4cdd50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_correlation_matrix(X, hurdle=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так же есть более автоматизированный метод поиска, основанный на собственных векторах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "corr = np.corrcoef(X, rowvar=0)\n",
    "eigenvalues, eigenvectors = np.linalg.eig(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Смотрим на собственные величины ищем самые маленькие и близкие нюлю."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmin(eigenvalues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берем соответсвующее значение и смотрим на собственный вектор."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.04552843, -0.08089873, -0.25126664,  0.03590431,  0.04389033,\n",
       "        0.04580522, -0.03870705, -0.01828389, -0.63337285,  0.72024335,\n",
       "        0.02350903, -0.00485021,  0.02477196])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvectors[:,8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Здесь так же находим выбивающиеся значение и смотрим, на каких переменных они получились."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('INDUS', 'RAD', 'TAX')\n"
     ]
    }
   ],
   "source": [
    "print (variables[2], variables[8], variables[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Это как раз те переменных, которые мы заметили на хит-мэп."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.24959319, -0.25652131,  0.3468611 ,  0.005099  ,  0.34297566,\n",
       "       -0.18943673,  0.31385097, -0.32173451,  0.31981745,  0.33853899,\n",
       "        0.20502118, -0.20273245,  0.30984085])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eigenvectors[:,0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнивать коэффициенты можно только после стандартизации, т.к. иначе в коэффициент будет заложена шкала того или иного признака."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "linear_regression = LinearRegression(normalize=False, fit_intercept=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "standardization = StandardScaler()\n",
    "Stand_coef_linear_reg = make_pipeline(standardization,\n",
    "                                      linear_regression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сначала выведем коэффициенты для изначальных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.796 NOX\n",
      " 3.805 RM\n",
      " 2.689 CHAS\n",
      " 1.476 DIS\n",
      " 0.953 PTRATIO\n",
      " 0.525 LSTAT\n",
      " 0.306 RAD\n",
      " 0.107 CRIM\n",
      " 0.046 ZN\n",
      " 0.021 INDUS\n",
      " 0.012 TAX\n",
      " 0.009 B\n",
      " 0.001 AGE\n"
     ]
    }
   ],
   "source": [
    "linear_regression.fit(X,y)\n",
    "\n",
    "for coef, var in sorted(zip(map(abs,linear_regression.coef_), \n",
    "           dataset.columns[:-1]), reverse=True):\n",
    "           print (\"%6.3f %s\" % (coef,var))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 3.749 LSTAT\n",
      " 3.104 DIS\n",
      " 2.671 RM\n",
      " 2.659 RAD\n",
      " 2.076 TAX\n",
      " 2.062 PTRATIO\n",
      " 2.060 NOX\n",
      " 1.081 ZN\n",
      " 0.920 CRIM\n",
      " 0.857 B\n",
      " 0.682 CHAS\n",
      " 0.143 INDUS\n",
      " 0.021 AGE\n"
     ]
    }
   ],
   "source": [
    "Stand_coef_linear_reg.fit(X,y)\n",
    "for coef, var in \\\n",
    "sorted(zip(map(abs,Stand_coef_linear_reg.steps[1][1].coef_), \\\n",
    "dataset.columns[:-1]), reverse=True):\n",
    "              print (\"%6.3f %s\" % (coef,var))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь можно потестиь r2_score поочередно исключая из модели ту или иную переменную."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline R2: 0.741\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "linear_regression = LinearRegression(normalize=False,\\\n",
    "                                                  fit_intercept=True)\n",
    "def r2_est(X,y):\n",
    "    return r2_score(y,linear_regression.fit(X,y).predict(X))\n",
    "\n",
    "print ('Baseline R2: %0.3f' %  r2_est(X,y)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0.057 LSTAT\n",
      " 0.044 RM\n",
      " 0.029 DIS\n",
      " 0.028 PTRATIO\n",
      " 0.011 NOX\n",
      " 0.011 RAD\n",
      " 0.006 B\n",
      " 0.006 ZN\n",
      " 0.006 TAX\n",
      " 0.006 CRIM\n",
      " 0.005 CHAS\n",
      " 0.000 INDUS\n",
      " 0.000 AGE\n"
     ]
    }
   ],
   "source": [
    "r2_impact = list()\n",
    "for j in range(X.shape[1]):\n",
    "    selection = [i for i in range(X.shape[1]) if i!=j]\n",
    "    r2_impact.append(((r2_est(X,y) - \\\n",
    "                       r2_est(X.values [:,selection],y)) ,dataset.columns[j]))\n",
    "\n",
    "for imp, varname in sorted(r2_impact, reverse=True):\n",
    "    print ('%6.3f %s' %  (imp, varname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Такой анализ называется partial r-square. \n",
    "\n",
    "Использую эти два способа отбора переменных можно исключить какие-нибудь. Важно помнить, что после каждого исключения нужно пересчитывать показатели важности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь об открытии нелинейных отношений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score\n",
    "linear_regression = LinearRegression(normalize=False,\\\n",
    "                                                  fit_intercept=True)\n",
    "create_interactions = PolynomialFeatures(degree=2, \\\n",
    "                                         interaction_only=True, include_bias=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def r2_est(X,y):\n",
    "    return r2_score(y,linear_regression.fit(X,y).predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline R2: 0.741\n"
     ]
    }
   ],
   "source": [
    "baseline = r2_est(X,y)\n",
    "print ('Baseline R2: %0.3f' % baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xi = create_interactions.fit_transform(X)\n",
    "main_effects = create_interactions.n_input_features_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если новая фича дает инкремент больше порога, то печатаем ее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding interaction     CRIM *    CHAS R2: 0.011\n",
      "Adding interaction     CRIM *      RM R2: 0.021\n",
      "Adding interaction       ZN *      RM R2: 0.013\n",
      "Adding interaction    INDUS *      RM R2: 0.038\n",
      "Adding interaction    INDUS *     DIS R2: 0.013\n",
      "Adding interaction      NOX *      RM R2: 0.027\n",
      "Adding interaction       RM *     AGE R2: 0.024\n",
      "Adding interaction       RM *     DIS R2: 0.018\n",
      "Adding interaction       RM *     RAD R2: 0.049\n",
      "Adding interaction       RM *     TAX R2: 0.054\n",
      "Adding interaction       RM * PTRATIO R2: 0.041\n",
      "Adding interaction       RM *       B R2: 0.020\n",
      "Adding interaction       RM *   LSTAT R2: 0.064\n"
     ]
    }
   ],
   "source": [
    "for k,effect in enumerate(create_interactions.powers_[(main_effects):]):\n",
    "    termA, termB = variables[effect==1]\n",
    "    increment = r2_est(Xi[:,list(range(0,main_effects)) \\\n",
    "                          +[main_effects+k]],y) - baseline\n",
    "    if increment > 0.01:\n",
    "        print ('Adding interaction %8s *%8s R2: %5.3f' %  \\\n",
    "          (termA, termB, increment))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 of a model with RM*LSTAT interaction: 0.805\n"
     ]
    }
   ],
   "source": [
    "Xi = X\n",
    "Xi['interaction'] = X['RM']*X['LSTAT']\n",
    "print ('R2 of a model with RM*LSTAT interaction: %0.3f' % \\\n",
    "       r2_est(Xi,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Следующая строка избавляет от научной нотации типа 1e-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=5, suppress=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Трансформации признаков для того чтобы пофиксить нелинейность\n",
    "\n",
    "|Function names| Functions|Comment|\n",
    "|-------------------|--------------------|------------------------|\n",
    "|Logarithmic|np.log(x)| Можно добавить константу np.log(x+1) |\n",
    "|Exponential|np.exp(x)|-|\n",
    "|Squared|x**2|-|\n",
    "|Cubed|x**3|-|\n",
    "|Square root|np.sqrt(x)|-|\n",
    "|Cube root|x**(1./3.)|-|\n",
    "|Inverse|1. / x|-|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Эта книга просто кладезь крутых тем. https://www.packtpub.com/big-data-and-business-intelligence/regression-analysis-python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "“If you are wondering what kind of regularization to use first, ridge or lasso, a good rule of thumb is to first run a linear regression without any regularization and check the distribution of the standardized coefficients. If there are many with similar values, then ridge is the best choice; if instead you notice that there are a few important coefficients and many lesser ones, using lasso is advisable to remove the unimportant ones. In any case, when you have more variables than observations, you should always use lasso.”\n",
    "\n",
    "Excerpt From: Luca Massaron. “Regression Analysis with Python.” iBooks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Глава про genelize - просто бомба!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
